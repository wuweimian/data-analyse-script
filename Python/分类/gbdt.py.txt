# -*- coding: utf-8 -*-


import genvs as GENV
G_ENV = GENV.GENVS()

import pandas as pd
import sklearn.metrics
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
from sklearn.metrics import precision_recall_fscore_support
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import report

def show_data_head(des_dir, n=10):
    df = G_ENV.get_features_data_all().head(n)
    report.savedataframe(des_dir, "特征数据预览", df)


################################################################################################
def model_evaluate(model, x_train, x_test, y_train, y_test):
    y_train_pred = model.predict(x_train)
    y_test_pred = model.predict(x_test)
    result_str = "类别|准确率\n"
    result_str += "{}|{}\n".format("训练集准确率",accuracy_score(y_train, y_train_pred))
    result_str += "{}|{}\n".format("测试集准确率", accuracy_score(y_test, y_test_pred))
    result_str2 = "类别|精确率|召回率|F值|测试数量\n"
    if hasattr(model, 'predict_proba'):
        y_score = model.predict_proba(x_test)
        y_hat = model.predict(x_test)

    gbdt_report = classification_report(y_test, y_hat)
    lines = gbdt_report.splitlines()
    res = []
    for row in lines[2:-2]:
       rows = row.split('      ')
       result_str2 += "{}|{}|{}|{}|{}\n".format(rows[1].replace(' ', ''), rows[2].replace(' ', ''), rows[3].replace(' ', ''), rows[4].replace(' ', ''), rows[5].replace(' ', ''))

    fpr, tpr, thresholds = sklearn.metrics.roc_curve(y_test, y_score[:, 1])
    auc = sklearn.metrics.auc(fpr, tpr)
    result_str += "{}|{}\n".format("auc值", auc)
    # 保存结果
    report.savestrtb(G_ENV.get_result_dir(), "GBDT模型评估结果", result_str)
    report.savestrtb(G_ENV.get_result_dir(), "GBDT测试集结果", result_str2)

def gbdts(x_col,y_col, train_size,criterion,init,learning_rate,loss,max_depth,
          max_features,max_leaf_nodes
          ):
    col = x_col+"|"+y_col
    df = G_ENV.get_features_data(col)
    df = df.dropna()
    col_list = x_col.split('|')
    x = (df[col_list]).values
    y = df[y_col].values
    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size, random_state=0)
    if init == 'None':
        init = None
    if max_features == 'None':
        max_features = None
    if max_leaf_nodes == 'None':
        max_leaf_nodes = None
    GBDT = GradientBoostingClassifier(criterion=criterion,init=init,learning_rate=learning_rate,
                                      loss=loss,max_depth=max_depth,max_features=max_features,
                                      max_leaf_nodes=max_leaf_nodes)
    model_GBDT = GBDT.fit(x_train, y_train)

    #持久化
    report.saveskmd(G_ENV.get_result_dir(), "模型实例", model_GBDT)

    model_evaluate(model_GBDT, x_train, x_test, y_train, y_test)
    #生成报告
    report.createhtml("运行结果", G_ENV.get_result_dir())

########################################################################################
# 以下是模板
if (__name__ == '__main__') & ('XXJOB' not in globals()):
    G_ENV.baseDir="C:/Users/Tim/Desktop/automodel/V2/data"
    G_ENV.projectId = "projectId"
    G_ENV.jobId="jobId"
    G_ENV.instanceId="instanceId"
    x_col = "2g_liuliang|total_liuliang|3g_liuliang|country_liuliang|mangshi_liuliang|arpu|xianshi_liuliang|province_liuliang"
    train_size = 0.7
    n_estimators = 10
    learning_rate = 0.1
    max_depth = 8
    criterion = 'friedman_mse'
    init = None
    learning_rate = 0.1
    loss = 'deviance'
    max_depth = 8
    max_features = None
    max_leaf_nodes = None,
    gbdts(x_col,"flag",train_size,criterion,init,learning_rate,loss,max_depth,max_features,max_leaf_nodes)
